import json
import re
from collections import Counter, defaultdict

import pandas as pd
from tqdm import tqdm

tqdm.pandas()


# TODO: Create list of tuples of reading and glyph

INFILE = "3_cleaned_transliterations.csv"
OUTFILE = "5_with_glyphs.csv"


# =============================================================================
# ====================== MAPPINGS / CONSTANTS =================================
# =============================================================================
MAPPINGS_DIR = "."
with open(f"{MAPPINGS_DIR}/wordform_to_glyph_names.json", encoding="utf-8") as infile:
    WORDFORM_TO_GLYPH_NAMES = json.load(infile)

with open(f"{MAPPINGS_DIR}/morpheme_to_glyph_names.json", encoding="utf-8") as infile:
    MORPHEME_TO_GLYPH_NAMES = json.load(infile)

with open(f"{MAPPINGS_DIR}/glyph_name_to_glyph.json", encoding="utf-8") as infile:
    GLYPH_NAME_TO_UNICODE = json.load(infile)


GLYPH_NAMES = set(GLYPH_NAME_TO_UNICODE.keys())

GLYPH_NAMES_TO_READINGS = defaultdict(set)
for reading, glyph_names in MORPHEME_TO_GLYPH_NAMES.items():
    for glyph_name in glyph_names:
        GLYPH_NAMES_TO_READINGS[glyph_name].add(reading)
for k, v in GLYPH_NAMES_TO_READINGS.items():
    GLYPH_NAMES_TO_READINGS[k] = list(v)

SPECIAL_TOKENS = {
    "==SURFACE==",
    "==COLUMN==",
    "==BLANK_SPACE==",
    "==RULING==",
    "...",
    "\n",
    "<unk>",
}

UNK = "<unk>"

NUMBERS_TO_TRANSLIT = {
    "1/2": "1/2(diÅ¡)",
    "1/3": "1/3(diÅ¡)",
    "2/3": "2/3(diÅ¡)",
    "5/6": "2/3(diÅ¡)",
    "1": "1(diÅ¡)",
    "2": "2(diÅ¡)",
    "3": "3(diÅ¡)",
    "4": "4(diÅ¡)",
    "5": "5(diÅ¡)",
    "6": "6(diÅ¡)",
    "7": "7(diÅ¡)",
    "8": "8(diÅ¡)",
    "9": "9(diÅ¡)",
    "10": "1(u)",
    "11": "1(u) 1(diÅ¡)",
    "12": "1(u) 2(diÅ¡)",
    "14": "1(u) 4(diÅ¡)",
    "18": "1(u) 8(diÅ¡)",
    "20": "2(u)",
    "21": "2(u) 1(diÅ¡)",
    "23": "2(u) 3(diÅ¡)",
    "24": "2(u) 4(diÅ¡)",
    "25": "2(u) 5(diÅ¡)",
    "30": "3(u)",
    "36": "3(u) 6(diÅ¡)",
    "40": "4(u)",
    "50": "5(u)",
    "60": "6(u)",
    "ð’Ž™ð’Š": "25",
    "600": "1(geÅ¡Ê¾u)",
    "900": "1(geÅ¡Ê¾u) 5(geÅ¡â‚‚)",
    "3600": "1(Å¡arÊ¾u@c)",
    "36000": "1(Å¡arâ‚‚)",
}

# As far as I can tell, there are at most 2 ways to do fractions
UNIT_CONVERSIONS = {
    "1/2(aÅ¡)": "1/2(diÅ¡)",
    "1/3(aÅ¡)": "1/3(diÅ¡)",
    "2/3(aÅ¡)": "2/3(diÅ¡)",
    "1/4(aÅ¡)": "1/4(iku)",
    "5/6(aÅ¡)": "2/3(diÅ¡)",
}


NUMERIC_PATTERN = re.compile(r"^\d+(/\d+)?(\.\d+)?(\s*\([^)]+\))?$")

# Places where convention has changed since the transliterations were made
MORPHEME_REPLACEMENTS = {
    # reading -> reading
    "babila": "babilim",
    "eriâ‚â‚ƒ": "ereâ‚â‚ƒ",
    "eriÅ¡â‚‚": "ereÅ¡â‚‚",
    "ilduâ‚“(NAGAR)": "nagar",
    "Å¡aganâ‚“(AMA)": "daÅ‹al",
    "Å¡u+niginâ‚‚": "Å¡uniÅ‹in",
    "Å¡u+nigin": "Å¡uniÅ‹in",
    # reading(SIGN) -> reading | reading(SIGN)
    "adâ‚†": "adâ‚†(|LUâ‚‚.LAGABÃ—U|)",
    "dabâ‚“(|LAGABÃ—(GUD&GUD)|)": "dibâ‚“(|LAGABÃ—(GUD&GUD)|)",
    "erinâ‚“(KWU896)": "erenâ‚“(KWU896)",
    "gurumâ‚“(|IGI.ERIM|)": "gurumâ‚‚",
    "itiâ‚“(|UD@sÃ—BAD|)": "itiâ‚‚(|UD@sÃ—BAD|)",
    "kuâ‚“(KUâ‚„)": "kuâ‚„",
    "lumâ‚“(KWU354)": "lum",
    "mudâ‚“(LAK449)": "mudâ‚ƒ(LAK449)",
    "sangaâ‚“(|Å ID.GAR|)": "saÅ‹Å‹aâ‚“(|Å ID.GAR|)",
    "Å¡itaâ‚“(KWU777)": "Å¡ita",
    "tabâ‚“(MAN)": "tabâ‚„",
    "umbinâ‚“(|URâ‚‚Ã—KIDâ‚‚|)": "umbin(|URâ‚‚Ã—KIDâ‚‚|)",
    "uÅ¡urâ‚“(|LALâ‚‚Ã—TUGâ‚‚|)": "uÅ¡urâ‚“(|LALâ‚‚.TUGâ‚‚|)",
    "ugaâ‚“(NAGA)": "ugaâ‚ƒ",
    "zeâ‚“(SIGâ‚‡)": "ziâ‚“(IGI@g)",
    # SIGN -> SIGN
    "(Å E.1(AÅ ))": "(Å E.AÅ )",
    "(Å E.2(AÅ ))": "(Å E.AÅ .AÅ )",
    "||EZENÃ—BAD|.AN|": "|EZENÃ—BAD.AN|",
    "|Eâ‚‚.BALAG|": "|KID.BALAG|",
    "|NINDAâ‚‚Ã—(Å E.2(AÅ @c))|": "|NINDAâ‚‚Ã—(Å E.AÅ .AÅ )|",
    "BADâ‚ƒ": "|EZENÃ—BAD|",
    "BILâ‚‚": "NE@s",
    "DUâ‚ˆ": "DUH",
    "ERIM": "ERINâ‚‚",
    "GAG": "KAK",
    "GINâ‚‚": "DUNâ‚ƒ@g",
    "GUâ‚„": "GUD",
    "ITI": "|UDÃ—(U.U.U)|",
    "MUNUS": "SAL",
    "NIGâ‚‚": "GAR",
    "SILAâ‚„": "|GAâ‚‚Ã—PA|",
    "SIGâ‚‡": "IGI@g",
    "TURâ‚ƒ": "|NUN.LAGAR|",
    "UHâ‚ƒ": "KUÅ Uâ‚‚",
    "Uâ‚ˆ": "|LAGABÃ—(GUD&GUD)|",
    # same as above but must come after
    "||LAGABÃ—(GUD&GUD)|+HULâ‚‚|": "|LAGABÃ—(GUD&GUD)+HULâ‚‚|",
    # SIGN LIST -> SIGN
    "BAU377": "GIÅ ",  # technically GIÅ ~v...
    "KWU147": "LIL",
    "KWU354": "LUM",
    "KWU636": "KUâ‚„",
    "KWU777": "Å ITA",
    "KWU844": "|Eâ‚‚Ã—AÅ @t|",
    "LAK060": "|UÅ Ã—TAKâ‚„|",
    "LAK085": "|SIÃ—TAKâ‚„|",
    "LAK173": "KADâ‚…",
    "LAK175": "SANGAâ‚‚",
    "LAK218": "|ZU&ZU.SAR|",
    "LAK449": "|NUNUZ.ABâ‚‚|",
    "LAK524": "|ZUMÃ—TUGâ‚‚|",
    "LAK589": "GISAL",
    "LAK672a": "UÅ X",
    "LAK672b": "MUNSUB",
    "LAK720": "|LAK648Ã—(PAP.PAP.LUâ‚ƒ)|",
    "LAK769": "|LAGABÃ—AN|",
    "LAK777": "|DAG.KISIMâ‚…Ã—UÅ |",
}


# =============================================================================
# ======================= TRANSLIT -> GLYPH NAMES =============================
# =============================================================================
def _split_wordform_into_morphemes(wf: str) -> list[str]:
    pattern = r"(\{.*?\})"
    split_ = re.split(pattern, wf)
    split_ = [s for s in split_ if s]
    # Split on hyphens, but not within parentheses
    split_ = [re.split(r"-(?![^(]*\))", s) for s in split_]
    # flatten
    split_ = [s for sublist in split_ for s in sublist]
    split_ = [s for s in split_ if s]
    return split_


# Any of the values is None
unk_sign_names = []
unk_nums_ = []
unk_w_colon_ = []
unk_other_ = []


def _morpheme_to_glyph_names(morpheme: str) -> tuple[str, list[str]]:
    # 7 -> 7(diÅ¡)
    if morpheme in NUMBERS_TO_TRANSLIT:
        morpheme = NUMBERS_TO_TRANSLIT[morpheme]

    if morpheme == "geÅ¡â‚‚":
        morpheme = "Å‹eÅ¡â‚‚"

    # Numbers
    if morpheme[0].isdigit() and NUMERIC_PATTERN.match(morpheme):
        for mod in ("", "@90", "@c", "@t", "@v"):
            morpheme = morpheme.replace(mod, "")
        if morpheme in UNIT_CONVERSIONS:
            morpheme = UNIT_CONVERSIONS[morpheme]

        if morpheme in MORPHEME_TO_GLYPH_NAMES:
            return morpheme, MORPHEME_TO_GLYPH_NAMES[morpheme]
        if morpheme in GLYPH_NAMES:
            if "(DIÅ )" in morpheme or "(AÅ )" in morpheme:
                return morpheme.lower(), [morpheme]
            return morpheme, [morpheme]
        unk_nums_.append(morpheme)

    # already glyph name, reading uncertain
    if morpheme in GLYPH_NAMES:
        return UNK, [morpheme]

    # {ki} -> ki
    morpheme = morpheme.replace("{", "").replace("}", "")

    # layup
    if morpheme in MORPHEME_TO_GLYPH_NAMES:
        return morpheme, MORPHEME_TO_GLYPH_NAMES[morpheme]

    # Sign name but that sign is not in the list.
    # But since sign names are based on a valid reading,
    # we can lowercase it and check again to get the more standard glyph name.
    # Note: the lowercase version may not be the right reading,
    # but we'll use it anyway..a
    # It is the highest probability and introduces, I think,
    # a desirable amount of noise
    if morpheme.isupper():
        morpheme_ = morpheme.lower()
        if morpheme_.lower() in MORPHEME_TO_GLYPH_NAMES:
            return morpheme_, MORPHEME_TO_GLYPH_NAMES[morpheme_]
        # give up hope :/
        unk_sign_names.append(morpheme)
        return UNK, []

    elif ":" in morpheme:
        unk_w_colon_.append(morpheme)

    elif "(" in morpheme and ")" in morpheme:
        split_ = morpheme.split("(")
        morpheme_ = split_[0]
        glyph_name_ = split_[1].replace(")", "")

        if morpheme_ in MORPHEME_TO_GLYPH_NAMES:
            possible_glyph_names = MORPHEME_TO_GLYPH_NAMES[morpheme_]
            if len(possible_glyph_names) == 1:
                return morpheme_, possible_glyph_names
            if glyph_name_ in possible_glyph_names:
                return morpheme_, [glyph_name_]

        if glyph_name_ in GLYPH_NAMES_TO_READINGS:
            possible_readings = GLYPH_NAMES_TO_READINGS[glyph_name_]
            if len(possible_readings) == 1:
                return possible_readings[0], [glyph_name_]
    unk_other_.append(morpheme)
    return morpheme, []


all_unk = []
could_add = []


def wordform_to_morphemes_and_glyph_names(wf: str) -> tuple[str, list[str]]:
    """
    Params: wf (str) a wordform
    Returns: tuple of updated wordform and list of glyph names
    """

    if wf.startswith("+"):
        wf = wf[1:]
    if wf.endswith("+"):
        wf = wf[:-1]

    # 1) It's a special token
    # --------------------------------
    if wf in SPECIAL_TOKENS:
        return wf, [wf]

    # 2) Standardize and split the wordform into morphemes
    # --------------------------------
    for k, v in MORPHEME_REPLACEMENTS.items():
        wf = wf.replace(k, v)
    morphemes = _split_wordform_into_morphemes(wf)

    # 3) Get possible glyph names for each morpheme
    # --------------------------------
    morphemes_and_possible_glyph_names = [
        _morpheme_to_glyph_names(morpheme) for morpheme in morphemes
    ]

    # 4) If all morphemes have only one possible glyph name, we're done
    # --------------------------------
    glyph_names = []
    for morpheme, possible_glyph_names in morphemes_and_possible_glyph_names:
        if len(possible_glyph_names) != 1:
            all_unk.append(morpheme)
            glyph_names.append(UNK)
        else:
            could_add.append(morpheme)
            glyph_names.append(possible_glyph_names[0])
    return wf, glyph_names


def add_glyph_names(row):
    text = row["transliteration_clean"]

    # Gets it ready for tokenization
    text = text.replace("\n", " \n ")
    text = text.replace("...", " ... ")
    text = re.sub(r"(\n\(lugal[^\n]*\))+", "\n...", text)
    text = text.replace("gurâ‚“(|Å E.KIN|)Å¡eâ‚ƒ", "gurâ‚“(|Å E.KIN|)-Å¡eâ‚ƒ")
    text = re.sub(r"\ +", " ", text)

    translit = ""
    glyph_names = ""

    for wf in text.split(" "):
        if wf == "":
            continue
        new_wf, wf_glyph_names_ = wordform_to_morphemes_and_glyph_names(wf)
        translit += new_wf + " "
        glyph_names += " ".join(wf_glyph_names_) + " "

    row["glyph_names"] = glyph_names.strip()
    row["transliteration"] = translit.strip()
    return row


# =============================================================================
# ======================= GLYPH NAMES -> GLYPHS ===============================
# =============================================================================


unk_names = []
no_unicode = []
found_unicode = []


def _glyph_name_to_unicode(glyph_name: str) -> str:
    if glyph_name in SPECIAL_TOKENS:
        return glyph_name

    if glyph_name not in GLYPH_NAME_TO_UNICODE:
        unk_names.append(glyph_name)
        return UNK

    unicode = GLYPH_NAME_TO_UNICODE[glyph_name]
    if not unicode:
        no_unicode.append(glyph_name)
        return UNK

    found_unicode.append(glyph_name)
    return unicode


def add_glyphs(row):
    glyph_names = row["glyph_names"]
    glyphs = ""
    for glyph_name in glyph_names.split(" "):
        if glyph_name == "":
            continue
        unicode = _glyph_name_to_unicode(glyph_name)
        glyphs += unicode
    row["glyphs"] = glyphs.strip()
    return row


# =============================================================================
# =============================== MAIN ========================================
# =============================================================================
# TODO: get rid of wordform lookup
if __name__ == "__main__":
    # Load corpus
    df = pd.read_csv(INFILE).fillna("")

    # Add glyphs
    print("Adding glyph names...")
    df = df.progress_apply(add_glyph_names, axis=1)

    def _print_report(x, title):
        print()
        print(f"----- {title} -----")
        print(len(x))
        counter = Counter(x)
        top_20 = counter.most_common(50)
        for token, count in top_20:
            print(f" > {token} â€“ {count}")

    _print_report(unk_sign_names, "UNK SIGN NAMES")
    _print_report(unk_w_colon_, "UNK W/ COLON")
    _print_report(unk_nums_, "UNK NUMBERS")
    _print_report(unk_other_, "UNK OTHER")

    print()
    print("Could not convert:", len(all_unk))
    print("Could convert:", len(could_add))
    print()

    df["glyph_names"] = df["glyph_names"].str.replace(" UN ", " KALAM@g ")
    df["glyph_names"] = df["glyph_names"].str.replace(" Å ITAâ‚‚ ", " |Å ITA.GIÅ | ")
    df["glyph_names"] = df["glyph_names"].str.replace(" LAK524 ", " |ZUMÃ—TUGâ‚‚| ")
    df["glyph_names"] = df["glyph_names"].str.replace(" |Å Uâ‚‚.3xAN| ", " |Å Uâ‚‚.3Ã—AN| ")
    df["glyph_names"] = df["glyph_names"].str.replace(" DEâ‚‚ ", " |UMUMÃ—KASKAL| ")

    print("Adding glyphs...")
    df = df.progress_apply(add_glyphs, axis=1)

    _print_report(unk_names, "UNK NAMES")
    _print_report(no_unicode, "NO UNICODE")

    print()
    print("Could not convert:", len(unk_names))
    print("Had no unicode:", len(no_unicode))
    print("Could convert:", len(found_unicode))
    print()

    df["transliteration"] = df["transliteration"].str.replace(" \n ", "\n")
    df["transliteration"] = df["transliteration"].str.replace(" ...", "...")
    df["transliteration"] = df["transliteration"].str.replace("... ", "...")

    # see how many rows have the same transliteration
    print(
        "Rows with the same transliteration:",
        len(df) - len(df["transliteration"].unique()),
    )
    # print some examples
    print(df[df["transliteration"].map(df["transliteration"].value_counts() > 1)])
    # Drop duplicates
    df = df.drop_duplicates(subset=["transliteration"])
    print(
        "Rows with the same glyphs:",
        len(df) - len(df["glyphs"].unique()),
    )
    print(df[df["glyphs"].map(df["glyphs"].value_counts() > 1)])

    df = df[
        [
            "id",
            "period",
            "genre",
            "transliteration",
            "glyph_names",
            "glyphs",
        ]
    ]

    # Count glyphs
    def _count_glyph(glyphs):
        for special in SPECIAL_TOKENS:
            glyphs = glyphs.replace(special, "")
        glyphs = glyphs.replace(" ", "")
        return len(glyphs)

    # print total glyph count
    print("Total glyphs:", df["glyphs"].map(_count_glyph).sum())

    print(f"Writing to {OUTFILE}...")
    df.to_csv(OUTFILE, index=False, encoding="utf-8")
